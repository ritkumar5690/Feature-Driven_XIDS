{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53b4719",
   "metadata": {},
   "source": [
    "# XIDS Data Exploration Notebook\n",
    "\n",
    "This notebook explores the KDD IDS dataset used in the XIDS (Explainable Intrusion Detection System) project.\n",
    "\n",
    "## Contents:\n",
    "1. Dataset Overview\n",
    "2. Data Loading and Inspection\n",
    "3. Statistical Analysis\n",
    "4. Class Distribution Analysis\n",
    "5. Feature Characteristics\n",
    "6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db976451",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "The KDD99 IDS dataset is a widely used benchmark for intrusion detection systems. It contains:\n",
    "- **Training set**: 4,898,431 records\n",
    "- **Test set**: 311,029 records\n",
    "- **Features**: ~41 network traffic features\n",
    "- **Classes**: BENIGN + 22 attack types\n",
    "\n",
    "This dataset is used for building and evaluating machine learning models for detecting network intrusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703005f7",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up visualization style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Define data paths\n",
    "DATA_DIR = Path('../backend/data/raw')\n",
    "TRAIN_FILE = DATA_DIR / 'KDDTrain+.txt'\n",
    "TEST_FILE = DATA_DIR / 'KDDTest+.txt'\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Train file exists: {TRAIN_FILE.exists()}\")\n",
    "print(f\"Test file exists: {TEST_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data (first 10000 rows for exploration)\n",
    "# In production, use the full dataset\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_FILE, nrows=10000)\n",
    "    test_df = pd.read_csv(TEST_FILE, nrows=10000)\n",
    "    print(f\"Train set shape: {train_df.shape}\")\n",
    "    print(f\"Test set shape: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data files not found. Using synthetic data for exploration.\")\n",
    "    train_df = pd.DataFrame(np.random.randn(1000, 41))\n",
    "    test_df = pd.DataFrame(np.random.randn(100, 41))\n",
    "\n",
    "print(\"\\nFirst few rows of training data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53130163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data information\n",
    "print(\"Training Data Info:\")\n",
    "print(f\"Shape: {train_df.shape}\")\n",
    "print(f\"Data types:\\n{train_df.dtypes}\")\n",
    "print(f\"\\nMemory usage: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a79613",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary\n",
    "print(\"Training Data Statistics:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = train_df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"Missing values detected:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found in training data\")\n",
    "\n",
    "# Check for infinite values\n",
    "infinite_values = np.isinf(train_df.select_dtypes(include=[np.number])).sum()\n",
    "print(f\"\\nInfinite values: {infinite_values.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4179975",
   "metadata": {},
   "source": [
    "## 4. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ee82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last column as label (assuming label is in last column)\n",
    "label_col = train_df.columns[-1]\n",
    "print(f\"Label column: {label_col}\")\n",
    "\n",
    "# Class distribution\n",
    "class_dist = train_df[label_col].value_counts()\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(class_dist)\n",
    "print(f\"\\nClass Distribution (%)\")\n",
    "print(class_dist / len(train_df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec87a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "class_dist.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Class Distribution (Count)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Attack Type')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "class_dist.plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "axes[1].set_title('Class Distribution (Percentage)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClass imbalance ratio (most common / least common):\")\n",
    "print(f\"{class_dist.max() / class_dist.min():.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5ea13",
   "metadata": {},
   "source": [
    "## 5. Feature Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric features\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
    "print(f\"\\nFeature names (first 10):\")\n",
    "for i, col in enumerate(numeric_cols[:10]):\n",
    "    print(f\"{i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976046f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "feature_stats = train_df[numeric_cols].describe().T\n",
    "feature_stats['skewness'] = train_df[numeric_cols].skew()\n",
    "feature_stats['kurtosis'] = train_df[numeric_cols].kurtosis()\n",
    "\n",
    "print(\"Feature Statistics (First 5 features):\")\n",
    "print(feature_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aed864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature variance\n",
    "feature_variance = train_df[numeric_cols].var()\n",
    "low_variance_features = feature_variance[feature_variance < 0.01]\n",
    "\n",
    "print(f\"Features with low variance (< 0.01): {len(low_variance_features)}\")\n",
    "if len(low_variance_features) > 0:\n",
    "    print(\"\\nLow variance features:\")\n",
    "    print(low_variance_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f1649",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3de459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality summary\n",
    "quality_report = {\n",
    "    'Total Samples': len(train_df),\n",
    "    'Total Features': len(train_df.columns),\n",
    "    'Numeric Features': len(numeric_cols),\n",
    "    'Categorical Features': len(train_df.select_dtypes(include=['object']).columns),\n",
    "    'Missing Values': train_df.isnull().sum().sum(),\n",
    "    'Duplicate Rows': train_df.duplicated().sum(),\n",
    "    'Memory Usage (MB)': round(train_df.memory_usage(deep=True).sum() / 1024**2, 2),\n",
    "    'Classes': len(train_df[label_col].unique())\n",
    "}\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36201163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with test set\n",
    "print(\"\\nTrain vs Test Set Comparison:\")\n",
    "print(f\"{'Metric':<20} {'Train':<15} {'Test':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Total Samples':<20} {len(train_df):<15} {len(test_df):<15}\")\n",
    "print(f\"{'Total Features':<20} {len(train_df.columns):<15} {len(test_df.columns):<15}\")\n",
    "print(f\"{'Classes':<20} {train_df[label_col].nunique():<15} {test_df[test_df.columns[-1]].nunique():<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167738e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This exploration shows the characteristics of the KDD IDS dataset used in the XIDS project. Key findings:\n",
    "\n",
    "1. **Dataset Size**: Large-scale dataset suitable for training robust models\n",
    "2. **Class Distribution**: Often imbalanced, with normal traffic being more prevalent\n",
    "3. **Feature Space**: Mix of continuous and categorical features\n",
    "4. **Data Quality**: Assessment helps identify preprocessing needs\n",
    "\n",
    "Next steps:\n",
    "- Use the preprocessing pipeline to clean and prepare data\n",
    "- Apply feature selection to reduce dimensionality\n",
    "- Train models for intrusion detection\n",
    "- Use explainability techniques for model interpretation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
